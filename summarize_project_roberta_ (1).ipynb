{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QuG1bnzx4zZk",
   "metadata": {
    "id": "QuG1bnzx4zZk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27dd2464",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27dd2464",
    "outputId": "bd2cac49-3162-4b77-d47a-3629850dddde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets==1.0.2 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==1.0.2) (1.23.3)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==1.0.2) (10.0.1)\n",
      "Requirement already satisfied: dill in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==1.0.2) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==1.0.2) (1.5.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==1.0.2) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==1.0.2) (4.64.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==1.0.2) (3.9.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets==1.0.2) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets==1.0.2) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets==1.0.2) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets==1.0.2) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets==1.0.2) (2022.9.24)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->datasets==1.0.2) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets==1.0.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets==1.0.2) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets==1.0.2) (1.16.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.27.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: rouge_score in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge_score) (1.3.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge_score) (1.23.3)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk->rouge_score) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets==1.0.2\n",
    "!pip install transformers\n",
    "#!rm seq2seq_trainer.py\n",
    "#!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/seq2seq/seq2seq_trainer.py\n",
    "!pip install rouge_score\n",
    "\n",
    "import datasets\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "#Tokenizer\n",
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "#Encoder-Decoder Model\n",
    "from transformers import EncoderDecoderModel\n",
    "\n",
    "#Training\n",
    "from transformers.trainer_seq2seq import Seq2SeqTrainer\n",
    "from transformers import TrainingArguments\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac2f02a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "ac2f02a5",
    "outputId": "2b9c3ea6-c4ce-4ab8-e796-bdca6fb78438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 152\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today is  Vasant Panchami. My parents say it i...</td>\n",
       "      <td>The story is about Meenu celebrating Vasant Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alfi was in the garden blowingbubbles.The bubb...</td>\n",
       "      <td>The text tells the story of Alfi, a boy blowin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This book belongs toFoxy Joxy  Plays A TrickWa...</td>\n",
       "      <td>The text is a short story about Foxy Joxy, a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Madhavpur was a village adjoining a wild life ...</td>\n",
       "      <td>The village of Madhavpur is located next to a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It’s  easy  to  see   animals  in  the zoo.   ...</td>\n",
       "      <td>The text discusses how animals are not just fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Today is  Vasant Panchami. My parents say it i...   \n",
       "1  Alfi was in the garden blowingbubbles.The bubb...   \n",
       "2  This book belongs toFoxy Joxy  Plays A TrickWa...   \n",
       "3  Madhavpur was a village adjoining a wild life ...   \n",
       "4  It’s  easy  to  see   animals  in  the zoo.   ...   \n",
       "\n",
       "                                             summary  \n",
       "0  The story is about Meenu celebrating Vasant Pa...  \n",
       "1  The text tells the story of Alfi, a boy blowin...  \n",
       "2  The text is a short story about Foxy Joxy, a s...  \n",
       "3  The village of Madhavpur is located next to a ...  \n",
       "4  The text discusses how animals are not just fo...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"keybert_text.csv\")[['text', 'summary']]\n",
    "print(\"Data size:\",len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "QCAseDPIR652",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QCAseDPIR652",
    "outputId": "184e1e55-7720-444e-d5a3-ecb1dd6ac210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (1.23.3)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: dill in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (1.5.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfceac73",
   "metadata": {
    "id": "cfceac73"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "train_data=Dataset.from_pandas(df[0:61])\n",
    "val_data=Dataset.from_pandas(df[61:122])\n",
    "test_data=Dataset.from_pandas(df[122:152])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b36e1dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b36e1dc",
    "outputId": "cbe8d5fe-b94c-4d70-a401-0858301fe9fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(features: {'text': Value(dtype='string', id=None), 'summary': Value(dtype='string', id=None)}, num_rows: 61)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "DvXK6CA3S-FO",
   "metadata": {
    "id": "DvXK6CA3S-FO"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "TA-TpvhHmtMd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TA-TpvhHmtMd",
    "outputId": "5605cf0c-f489-47c8-8983-a8f9063d5b8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: dill==0.3.5.1 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall dill\n",
    "!pip install dill==0.3.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2d6f32a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "9ee3a9ef6ddd4d1eb3b30ef6f76657a5",
      "af1c9097edc948eaa77fd5fdd19830e6",
      "63a4284f715a47b4b04d91efe26f6d22",
      "3c6892695afa4f08ada127db7561e86e",
      "2dba7ebe56cc4cebb99d9b7387211de1",
      "505bfcaa00bd44a3979b0846c91eb0d6",
      "d0bf9b559efd419ea54bc03ac8296291",
      "72c47f55dcfc488cb53ec6597f1cb69e",
      "f5ceae3cf4ca41b08d5278d3ddc871d5",
      "9da71713705b480f8c380779278ca660",
      "22f17594f287485f936e2da26e667ef9",
      "5cf434174d4641d18d3f462aa32b05ee",
      "acd66da712b84d239d45b27e987cf0c2",
      "1ad0acfaff4d4f9c9239953071cae73f",
      "202288365dce4647aecc93312aabbade",
      "446ff07466824959a0a31dded2f73ecc",
      "9c02a9c8cb004d42bf6b95c41a6fcf24",
      "3549f062e24640d083b9aa5969c22907",
      "e4be440f787948d4ba8a0fc70b1e6012",
      "5cd7e037b9634d1e880a56b88bbbb838",
      "c6a50164c41a4506bae32854979e662f",
      "022715bd72544b6684696f50c663c766"
     ]
    },
    "id": "e2d6f32a",
    "outputId": "542058ae-6346-4015-9aa9-a7e5605cf96d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_10052\\3676487541.py\", line 27, in <module>\n",
      "    train_data = train_data.map(\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py\", line 1228, in map\n",
      "    return self._map_single(\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py\", line 153, in wrapper\n",
      "    out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\fingerprint.py\", line 157, in wrapper\n",
      "    kwargs[fingerprint_name] = update_fingerprint(\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\fingerprint.py\", line 105, in update_fingerprint\n",
      "    hasher.update(transform_args[key])\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\fingerprint.py\", line 57, in update\n",
      "    self.m.update(self.hash(value).encode(\"utf-8\"))\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\fingerprint.py\", line 53, in hash\n",
      "    return cls.hash_default(value)\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\fingerprint.py\", line 46, in hash_default\n",
      "    return cls.hash_bytes(dumps(value))\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\utils\\py_utils.py\", line 367, in dumps\n",
      "    dump(obj, file)\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\utils\\py_utils.py\", line 339, in dump\n",
      "    Pickler(file, recurse=True).dump(obj)\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dill\\_dill.py\", line 394, in dump\n",
      "    #     \"\"\"unpickle an object from a compressed string\"\"\"\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pickle.py\", line 487, in dump\n",
      "    self.save(obj)\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dill\\_dill.py\", line 388, in save\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pickle.py\", line 560, in save\n",
      "    f(self, obj)  # Call unbound method with explicit self\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dill\\_dill.py\", line 1824, in save_function\n",
      "    _dict = _dict_from_dictproxy(obj.__dict__)\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dill\\_dill.py\", line 1070, in _save_with_postproc\n",
      "    if type(attr) is DictProxyType:\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pickle.py\", line 692, in save_reduce\n",
      "    save(args)\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dill\\_dill.py\", line 388, in save\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pickle.py\", line 560, in save\n",
      "    f(self, obj)  # Call unbound method with explicit self\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pickle.py\", line 902, in save_tuple\n",
      "    save(element)\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dill\\_dill.py\", line 388, in save\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pickle.py\", line 560, in save\n",
      "    f(self, obj)  # Call unbound method with explicit self\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\utils\\py_utils.py\", line 386, in _save_code\n",
      "    dill._dill.log.info(\"Co: %s\" % obj)\n",
      "AttributeError: module 'dill._dill' has no attribute 'log'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1997, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1112, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1006, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 859, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 812, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 730, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "tokenizer.bos_token = tokenizer.cls_token\n",
    "tokenizer.eos_token = tokenizer.sep_token\n",
    "#parameter setting\n",
    "batch_size=256  #\n",
    "encoder_max_length=40\n",
    "decoder_max_length=8\n",
    "\n",
    "def process_data_to_model_inputs(batch):\n",
    "  # tokenize the inputs and labels\n",
    "  inputs = tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
    "  outputs = tokenizer(batch[\"summary\"], padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n",
    "\n",
    "  batch[\"input_ids\"] = inputs.input_ids\n",
    "  batch[\"attention_mask\"] = inputs.attention_mask\n",
    "  batch[\"decoder_input_ids\"] = outputs.input_ids\n",
    "  batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
    "  batch[\"labels\"] = outputs.input_ids.copy()\n",
    "\n",
    "  # because RoBERTa automatically shifts the labels, the labels correspond exactly to `decoder_input_ids`. \n",
    "  # We have to make sure that the PAD token is ignored\n",
    "  batch[\"labels\"] = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n",
    "\n",
    "  return batch\n",
    "\n",
    "#processing training data\n",
    "train_data = train_data.map(\n",
    "    process_data_to_model_inputs, \n",
    "    batched=True, \n",
    "    batch_size=batch_size, \n",
    "    remove_columns=[\"text\", \"summary\"]\n",
    ")\n",
    "train_data.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    ")\n",
    "\n",
    "#processing validation data\n",
    "val_data = val_data.map(\n",
    "    process_data_to_model_inputs, \n",
    "    batched=True, \n",
    "    batch_size=batch_size, \n",
    "    remove_columns=[\"text\", \"summary\"]\n",
    ")\n",
    "val_data.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89cdf6cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178,
     "referenced_widgets": [
      "304942949e3b4409aafce5f341396334",
      "b82690564f3e42e8a551dc9ddb20128a",
      "e67560d5ba9b4b6092c8cd5e4463e185",
      "f75b43fcd9384117913d68dc351ecdcd",
      "6edce8734740439d90f08f086c0d687a",
      "5dccc9b45b3649089eb9e41ed93849f2",
      "d5e549fe79bf4e3f9ac4e640c7215055",
      "fc6da17784e74bde953b00be32dbfad0",
      "12ad0e47332943eab2e0e64eb5135995",
      "b54ac5c1454243f69a7a448a00a872d2",
      "ea5f21dbb9c24b3ca8d6ff5671013768"
     ]
    },
    "id": "89cdf6cc",
    "outputId": "0d258d25-f932-49dd-d51b-de34ad3219ee"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5388771f9b11443ca12dfd71a4432916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.encoder.layer.10.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.11.crossattention.self.query.weight', 'roberta.encoder.layer.10.crossattention.self.value.weight', 'roberta.encoder.layer.8.crossattention.output.dense.bias', 'roberta.encoder.layer.6.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.6.crossattention.self.key.weight', 'roberta.encoder.layer.9.crossattention.self.query.weight', 'roberta.encoder.layer.7.crossattention.self.value.bias', 'roberta.encoder.layer.8.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.9.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.6.crossattention.output.dense.weight', 'roberta.encoder.layer.10.crossattention.output.dense.bias', 'roberta.encoder.layer.7.crossattention.self.query.bias', 'roberta.encoder.layer.11.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.8.crossattention.self.key.bias', 'roberta.encoder.layer.9.crossattention.self.value.bias', 'roberta.encoder.layer.11.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.10.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.11.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.6.crossattention.self.query.bias', 'roberta.encoder.layer.9.crossattention.output.dense.bias', 'roberta.encoder.layer.9.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.8.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.self.value.weight', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.7.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.9.crossattention.self.value.weight', 'roberta.encoder.layer.10.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.6.crossattention.self.value.bias', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.11.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.8.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.9.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.7.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.10.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.8.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.10.crossattention.self.value.bias', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.6.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention.self.query.weight', 'roberta.encoder.layer.6.crossattention.output.dense.bias', 'roberta.encoder.layer.10.crossattention.self.query.weight', 'roberta.encoder.layer.11.crossattention.self.query.bias', 'roberta.encoder.layer.8.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.7.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.7.crossattention.output.dense.weight', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.9.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.7.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.7.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.10.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following encoder weights were not tied to the decoder ['roberta/pooler']\n"
     ]
    }
   ],
   "source": [
    "from transformers import EncoderDecoderModel\n",
    "\n",
    "roberta_shared = EncoderDecoderModel.from_encoder_decoder_pretrained(\"roberta-base\", \"roberta-base\", tie_encoder_decoder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "813c8a01",
   "metadata": {
    "id": "813c8a01"
   },
   "outputs": [],
   "source": [
    "# set special tokens\n",
    "roberta_shared.config.decoder_start_token_id = tokenizer.bos_token_id                                             \n",
    "roberta_shared.config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# sensible parameters for beam search\n",
    "# set decoding params                               \n",
    "roberta_shared.config.max_length = 40\n",
    "roberta_shared.config.early_stopping = True\n",
    "roberta_shared.config.no_repeat_ngram_size = 3\n",
    "roberta_shared.config.length_penalty = 2.0\n",
    "roberta_shared.config.num_beams = 4\n",
    "roberta_shared.config.vocab_size = roberta_shared.config.encoder.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f84e2e37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f84e2e37",
    "outputId": "7778be0f-5161-4b46-afc2-f1d671a49207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderDecoderModel(\n",
      "  (encoder): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): RobertaPooler(\n",
      "      (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (decoder): RobertaForCausalLM(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): RobertaEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x RobertaLayer(\n",
      "            (attention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "                (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "                (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (crossattention): RobertaAttention(\n",
      "              (self): RobertaSelfAttention(\n",
      "                (query): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "                (key): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "                (value): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): RobertaSelfOutput(\n",
      "                (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): RobertaIntermediate(\n",
      "              (dense): DynamicQuantizedLinear(in_features=768, out_features=3072, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): RobertaOutput(\n",
      "              (dense): DynamicQuantizedLinear(in_features=3072, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (lm_head): RobertaLMHead(\n",
      "      (dense): DynamicQuantizedLinear(in_features=768, out_features=768, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (decoder): DynamicQuantizedLinear(in_features=768, out_features=50265, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import torch\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    roberta_shared, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "print(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04ec32da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04ec32da",
    "outputId": "3f8f7f5d-ab0c-41bd-9275-800f99c63174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 614.781149\n",
      "Size (MB): 395.20181\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')\n",
    "\n",
    "print_size_of_model(roberta_shared)\n",
    "print_size_of_model(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "711ba55d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "id": "711ba55d",
    "outputId": "4cf1ca08-7546-4b8e-aab9-c09346db0fb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: regex in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2022.10.31)\n",
      "Requirement already satisfied: requests in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.28.1)\n",
      "Collecting hydra-core\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "     ------------------------------------ 154.5/154.5 kB 771.7 kB/s eta 0:00:00\n",
      "Collecting omegaconf\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "     ---------------------------------------- 79.5/79.5 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting bitarray\n",
      "  Downloading bitarray-2.7.3-cp310-cp310-win_amd64.whl (118 kB)\n",
      "     ------------------------------------ 118.2/118.2 kB 631.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2022.9.24)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from hydra-core)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "     -------------------------------------- 117.0/117.0 kB 1.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: packaging in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hydra-core) (21.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from omegaconf) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->hydra-core) (3.0.9)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144578 sha256=bf4ed024ff8a1f9744d5e2f492a360552e1a5c9e87d9af96f72fd3e136b8753d\n",
      "  Stored in directory: c:\\users\\msi\\appdata\\local\\pip\\cache\\wheels\\12\\93\\dd\\1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: bitarray, antlr4-python3-runtime, omegaconf, hydra-core\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 bitarray-2.7.3 hydra-core-1.3.2 omegaconf-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install regex requests hydra-core omegaconf bitarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "u6LG4eyHW8TX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u6LG4eyHW8TX",
    "outputId": "a053f0e2-08a3-4572-8916-df6811e4dc1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fairseq\n",
      "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
      "     ---------------------------------------- 9.6/9.6 MB 373.2 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: cffi in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fairseq) (1.15.1)\n",
      "Collecting cython (from fairseq)\n",
      "  Using cached Cython-0.29.34-py2.py3-none-any.whl (988 kB)\n",
      "Collecting hydra-core<1.1,>=1.0.7 (from fairseq)\n",
      "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
      "     -------------------------------------- 123.8/123.8 kB 1.0 MB/s eta 0:00:00\n",
      "Collecting omegaconf<2.1 (from fairseq)\n",
      "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: regex in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fairseq) (2022.10.31)\n",
      "Collecting sacrebleu>=1.4.12 (from fairseq)\n",
      "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "     -------------------------------------- 118.9/118.9 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fairseq) (2.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fairseq) (4.64.1)\n",
      "Requirement already satisfied: bitarray in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fairseq) (2.7.3)\n",
      "Collecting torchaudio>=0.8.0 (from fairseq)\n",
      "  Downloading torchaudio-2.0.1-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fairseq) (1.23.3)\n",
      "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq)\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "     ------------------------------------ 112.4/112.4 kB 817.3 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: PyYAML>=5.1.* in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from omegaconf<2.1->fairseq) (6.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from omegaconf<2.1->fairseq) (4.4.0)\n",
      "Collecting portalocker (from sacrebleu>=1.4.12->fairseq)\n",
      "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu>=1.4.12->fairseq)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\n",
      "Requirement already satisfied: lxml in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sacrebleu>=1.4.12->fairseq) (4.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->fairseq) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->fairseq) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->fairseq) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->fairseq) (3.1.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi->fairseq) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch->fairseq) (2.1.1)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from portalocker->sacrebleu>=1.4.12->fairseq) (304)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch->fairseq) (1.3.0)\n",
      "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
      "  Building wheel for fairseq (pyproject.toml): started\n",
      "  Building wheel for fairseq (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-win_amd64.whl size=10322847 sha256=70b2dbdf98b822f9ee3ded1916f7fad6d4f470f6bb81e5a11470c36c7464b484\n",
      "  Stored in directory: c:\\users\\msi\\appdata\\local\\pip\\cache\\wheels\\e4\\35\\55\\9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141217 sha256=a769931c4b577abceea9c9a1396151a15e5a870ca466d978f3807b91fe34d702\n",
      "  Stored in directory: c:\\users\\msi\\appdata\\local\\pip\\cache\\wheels\\a7\\20\\bd\\e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
      "Successfully built fairseq antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, tabulate, portalocker, omegaconf, cython, sacrebleu, hydra-core, torchaudio, fairseq\n",
      "  Attempting uninstall: antlr4-python3-runtime\n",
      "    Found existing installation: antlr4-python3-runtime 4.9.3\n",
      "    Uninstalling antlr4-python3-runtime-4.9.3:\n",
      "      Successfully uninstalled antlr4-python3-runtime-4.9.3\n",
      "  Attempting uninstall: omegaconf\n",
      "    Found existing installation: omegaconf 2.3.0\n",
      "    Uninstalling omegaconf-2.3.0:\n",
      "      Successfully uninstalled omegaconf-2.3.0\n",
      "  Attempting uninstall: hydra-core\n",
      "    Found existing installation: hydra-core 1.3.2\n",
      "    Uninstalling hydra-core-1.3.2:\n",
      "      Successfully uninstalled hydra-core-1.3.2\n",
      "Successfully installed antlr4-python3-runtime-4.8 cython-0.29.34 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.7.0 sacrebleu-2.3.1 tabulate-0.9.0 torchaudio-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b7814d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b7814d5",
    "outputId": "60940581-1d19-4421-aa9f-ee1922a408d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/fairseq/zipball/main\" to C:\\Users\\MSI/.cache\\torch\\hub\\main.zip\n",
      "2023-05-01 22:33:52 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build_ext\n",
      "cythoning fairseq/data/data_utils_fast.pyx to fairseq/data\\data_utils_fast.cpp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  warnings.warn(msg.format('we could not find ninja.'))\n",
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\cpp_extension.py:359: UserWarning: Error checking compiler version for cl: [WinError 2] Le fichier spécifié est introuvable\n",
      "  warnings.warn(f'Error checking compiler version for {compiler}: {error}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cythoning fairseq/data/token_block_utils_fast.pyx to fairseq/data\\token_block_utils_fast.cpp\n",
      "building 'fairseq.libbleu' extension\n",
      "creating build\n",
      "creating build\\temp.win-amd64-cpython-310\n",
      "creating build\\temp.win-amd64-cpython-310\\Release\n",
      "creating build\\temp.win-amd64-cpython-310\\Release\\fairseq\n",
      "creating build\\temp.win-amd64-cpython-310\\Release\\fairseq\\clib\n",
      "creating build\\temp.win-amd64-cpython-310\\Release\\fairseq\\clib\\libbleu\n",
      "\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\include -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22000.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\cppwinrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um\" /EHsc /Tpfairseq/clib/libbleu/libbleu.cpp /Fobuild\\temp.win-amd64-cpython-310\\Release\\fairseq/clib/libbleu/libbleu.obj /MD /wd4819 /wd4251 /wd4244 /wd4267 /wd4275 /wd4018 /wd4190 /EHsc -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\include -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22000.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\cppwinrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um\" /EHsc /Tpfairseq/clib/libbleu/module.cpp /Fobuild\\temp.win-amd64-cpython-310\\Release\\fairseq/clib/libbleu/module.obj /MD /wd4819 /wd4251 /wd4244 /wd4267 /wd4275 /wd4018 /wd4190 /EHsc -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "creating C:\\Users\\MSI\\.cache\\torch\\hub\\pytorch_fairseq_main\\build\\lib.win-amd64-cpython-310\n",
      "creating C:\\Users\\MSI\\.cache\\torch\\hub\\pytorch_fairseq_main\\build\\lib.win-amd64-cpython-310\\fairseq\n",
      "\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\bin\\HostX86\\x64\\link.exe\" /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\libs /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310 /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\lib\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.22000.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.22000.0\\\\um\\x64\" /EXPORT:PyInit_libbleu build\\temp.win-amd64-cpython-310\\Release\\fairseq/clib/libbleu/libbleu.obj build\\temp.win-amd64-cpython-310\\Release\\fairseq/clib/libbleu/module.obj /OUT:build\\lib.win-amd64-cpython-310\\fairseq\\libbleu.cp310-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-cpython-310\\Release\\fairseq/clib/libbleu\\libbleu.cp310-win_amd64.lib\n",
      "building 'fairseq.data.data_utils_fast' extension\n",
      "creating build\\temp.win-amd64-cpython-310\\Release\\fairseq\\data\n",
      "\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\include -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\include -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\include -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22000.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\cppwinrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um\" /EHsc /Tpfairseq/data\\data_utils_fast.cpp /Fobuild\\temp.win-amd64-cpython-310\\Release\\fairseq/data\\data_utils_fast.obj /MD /wd4819 /wd4251 /wd4244 /wd4267 /wd4275 /wd4018 /wd4190 /EHsc -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=data_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "creating C:\\Users\\MSI\\.cache\\torch\\hub\\pytorch_fairseq_main\\build\\lib.win-amd64-cpython-310\\fairseq\\data\n",
      "\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\bin\\HostX86\\x64\\link.exe\" /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\libs /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310 /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\lib\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.22000.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.22000.0\\\\um\\x64\" /EXPORT:PyInit_data_utils_fast build\\temp.win-amd64-cpython-310\\Release\\fairseq/data\\data_utils_fast.obj /OUT:build\\lib.win-amd64-cpython-310\\fairseq\\data\\data_utils_fast.cp310-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-cpython-310\\Release\\fairseq/data\\data_utils_fast.cp310-win_amd64.lib\n",
      "building 'fairseq.data.token_block_utils_fast' extension\n",
      "\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\include -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\include -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\include -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22000.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\cppwinrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um\" /EHsc /Tpfairseq/data\\token_block_utils_fast.cpp /Fobuild\\temp.win-amd64-cpython-310\\Release\\fairseq/data\\token_block_utils_fast.obj /MD /wd4819 /wd4251 /wd4244 /wd4267 /wd4275 /wd4018 /wd4190 /EHsc -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=token_block_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\bin\\HostX86\\x64\\link.exe\" /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\libs /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310 /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\lib\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.22000.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.22000.0\\\\um\\x64\" /EXPORT:PyInit_token_block_utils_fast build\\temp.win-amd64-cpython-310\\Release\\fairseq/data\\token_block_utils_fast.obj /OUT:build\\lib.win-amd64-cpython-310\\fairseq\\data\\token_block_utils_fast.cp310-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-cpython-310\\Release\\fairseq/data\\token_block_utils_fast.cp310-win_amd64.lib\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building 'fairseq.libbase' extension\n",
      "creating build\\temp.win-amd64-cpython-310\\Release\\fairseq\\clib\\libbase\n",
      "\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\include -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\include\\TH -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\include\\THC -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\include -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22000.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\cppwinrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um\" /EHsc /Tpfairseq/clib/libbase/balanced_assignment.cpp /Fobuild\\temp.win-amd64-cpython-310\\Release\\fairseq/clib/libbase/balanced_assignment.obj /MD /wd4819 /wd4251 /wd4244 /wd4267 /wd4275 /wd4018 /wd4190 /EHsc -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=libbase -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\bin\\HostX86\\x64\\link.exe\" /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\lib /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\libs /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310 /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\lib\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.22000.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.22000.0\\\\um\\x64\" c10.lib torch.lib torch_cpu.lib torch_python.lib /EXPORT:PyInit_libbase build\\temp.win-amd64-cpython-310\\Release\\fairseq/clib/libbase/balanced_assignment.obj /OUT:build\\lib.win-amd64-cpython-310\\fairseq\\libbase.cp310-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-cpython-310\\Release\\fairseq/clib/libbase\\libbase.cp310-win_amd64.lib\n",
      "building 'fairseq.libnat' extension\n",
      "creating build\\temp.win-amd64-cpython-310\\Release\\fairseq\\clib\\libnat\n",
      "\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\include -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\include\\TH -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\include\\THC -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\include -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22000.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\cppwinrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um\" /EHsc /Tpfairseq/clib/libnat/edit_dist.cpp /Fobuild\\temp.win-amd64-cpython-310\\Release\\fairseq/clib/libnat/edit_dist.obj /MD /wd4819 /wd4251 /wd4244 /wd4267 /wd4275 /wd4018 /wd4190 /EHsc -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=libnat -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\bin\\HostX86\\x64\\link.exe\" /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\lib /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\libs /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310 /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\lib\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.22000.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.22000.0\\\\um\\x64\" c10.lib torch.lib torch_cpu.lib torch_python.lib /EXPORT:PyInit_libnat build\\temp.win-amd64-cpython-310\\Release\\fairseq/clib/libnat/edit_dist.obj /OUT:build\\lib.win-amd64-cpython-310\\fairseq\\libnat.cp310-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-cpython-310\\Release\\fairseq/clib/libnat\\libnat.cp310-win_amd64.lib\n",
      "building 'alignment_train_cpu_binding' extension\n",
      "creating build\\temp.win-amd64-cpython-310\\Release\\examples\n",
      "creating build\\temp.win-amd64-cpython-310\\Release\\examples\\operators\n",
      "\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\include -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\include\\TH -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\include\\THC -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\include -IC:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22000.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22000.0\\\\cppwinrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um\" /EHsc /Tpexamples/operators/alignment_train_cpu.cpp /Fobuild\\temp.win-amd64-cpython-310\\Release\\examples/operators/alignment_train_cpu.obj /MD /wd4819 /wd4251 /wd4244 /wd4267 /wd4275 /wd4018 /wd4190 /EHsc -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=alignment_train_cpu_binding -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\bin\\HostX86\\x64\\link.exe\" /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\lib /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\libs /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310 /LIBPATH:C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.34.31933\\lib\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.22000.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.22000.0\\\\um\\x64\" c10.lib torch.lib torch_cpu.lib torch_python.lib /EXPORT:PyInit_alignment_train_cpu_binding build\\temp.win-amd64-cpython-310\\Release\\examples/operators/alignment_train_cpu.obj /OUT:build\\lib.win-amd64-cpython-310\\alignment_train_cpu_binding.cp310-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-cpython-310\\Release\\examples/operators\\alignment_train_cpu_binding.cp310-win_amd64.lib\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying build\\lib.win-amd64-cpython-310\\fairseq\\libbleu.cp310-win_amd64.pyd -> fairseq\n",
      "copying build\\lib.win-amd64-cpython-310\\fairseq\\data\\data_utils_fast.cp310-win_amd64.pyd -> fairseq\\data\n",
      "copying build\\lib.win-amd64-cpython-310\\fairseq\\data\\token_block_utils_fast.cp310-win_amd64.pyd -> fairseq\\data\n",
      "copying build\\lib.win-amd64-cpython-310\\fairseq\\libbase.cp310-win_amd64.pyd -> fairseq\n",
      "copying build\\lib.win-amd64-cpython-310\\fairseq\\libnat.cp310-win_amd64.pyd -> fairseq\n",
      "copying build\\lib.win-amd64-cpython-310\\alignment_train_cpu_binding.cp310-win_amd64.pyd -> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 22:34:36 | INFO | fairseq.file_utils | http://dl.fbaipublicfiles.com/fairseq/models/roberta.large.tar.gz not found in cache, downloading to C:\\Users\\MSI\\AppData\\Local\\Temp\\tmpcuyal5yu\n",
      "100%|█████████████████████████████████████████████████████████████████| 655283069/655283069 [19:42<00:00, 554224.34B/s]\n",
      "2023-05-01 22:54:18 | INFO | fairseq.file_utils | copying C:\\Users\\MSI\\AppData\\Local\\Temp\\tmpcuyal5yu to cache at C:\\Users\\MSI\\.cache\\torch\\pytorch_fairseq\\83e3a689e28e5e4696ecb0bbb05a77355444a5c8a3437e0f736d8a564e80035e.c687083d14776c1979f3f71654febb42f2bb3d9a94ff7ebdfe1ac6748dba89d2\n",
      "2023-05-01 22:54:19 | INFO | fairseq.file_utils | creating metadata file for C:\\Users\\MSI\\.cache\\torch\\pytorch_fairseq\\83e3a689e28e5e4696ecb0bbb05a77355444a5c8a3437e0f736d8a564e80035e.c687083d14776c1979f3f71654febb42f2bb3d9a94ff7ebdfe1ac6748dba89d2\n",
      "2023-05-01 22:54:19 | INFO | fairseq.file_utils | removing temp file C:\\Users\\MSI\\AppData\\Local\\Temp\\tmpcuyal5yu\n",
      "2023-05-01 22:54:19 | INFO | fairseq.file_utils | loading archive file http://dl.fbaipublicfiles.com/fairseq/models/roberta.large.tar.gz from cache at C:\\Users\\MSI\\.cache\\torch\\pytorch_fairseq\\83e3a689e28e5e4696ecb0bbb05a77355444a5c8a3437e0f736d8a564e80035e.c687083d14776c1979f3f71654febb42f2bb3d9a94ff7ebdfe1ac6748dba89d2\n",
      "2023-05-01 22:54:19 | INFO | fairseq.file_utils | extracting archive file C:\\Users\\MSI\\.cache\\torch\\pytorch_fairseq\\83e3a689e28e5e4696ecb0bbb05a77355444a5c8a3437e0f736d8a564e80035e.c687083d14776c1979f3f71654febb42f2bb3d9a94ff7ebdfe1ac6748dba89d2 to temp dir C:\\Users\\MSI\\AppData\\Local\\Temp\\tmply7yn39j\n",
      "2023-05-01 22:54:29 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-05-01 22:54:34 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 25, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 4, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1024, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 19237, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 200, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'mmap', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 500000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0004], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1024}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=25, log_format='json', tbmf_wrapper=False, seed=4, cpu=False, fp16=True, memory_efficient_fp16=True, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=2, skip_invalid_size_inputs_valid_test=True, max_tokens=4400, max_sentences=8, required_batch_size_multiple=1, dataset_impl='mmap', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, only_validate=False, max_sentences_valid=8, curriculum=0, distributed_world_size=1024, distributed_rank=0, distributed_backend='nccl', distributed_port=19237, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=200, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=0, max_update=500000, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0004], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=2000, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.01, force_anneal=None, warmup_updates=24000, end_learning_rate=0.0, power=1.0, total_num_update=500000, sample_break_mode='complete', tokens_per_sample=512, mask_prob=0.15, leave_unmasked_prob=0.1, random_token_prob=0.1, activation_fn='gelu', dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, pooler_activation_fn='tanh', max_positions=512, activation_dropout=0.0, load_checkpoint_heads=True, data='C:\\\\Users\\\\MSI\\\\.cache\\\\torch\\\\pytorch_fairseq\\\\83e3a689e28e5e4696ecb0bbb05a77355444a5c8a3437e0f736d8a564e80035e.c687083d14776c1979f3f71654febb42f2bb3d9a94ff7ebdfe1ac6748dba89d2', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', pooler_dropout=0.0, no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'C:\\\\Users\\\\MSI\\\\.cache\\\\torch\\\\pytorch_fairseq\\\\83e3a689e28e5e4696ecb0bbb05a77355444a5c8a3437e0f736d8a564e80035e.c687083d14776c1979f3f71654febb42f2bb3d9a94ff7ebdfe1ac6748dba89d2', 'sample_break_mode': 'complete', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 4, 'include_target_tokens': False, 'include_index': True, 'skip_masking': False, 'd2v2_multi': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [0.0004]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 24000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 500000.0, 'lr': [0.0004]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 22:54:35 | INFO | fairseq.file_utils | https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json not found in cache, downloading to C:\\Users\\MSI\\AppData\\Local\\Temp\\tmpce0rn_bo\n",
      "1042301B [00:02, 433327.42B/s]\n",
      "2023-05-01 22:54:40 | INFO | fairseq.file_utils | copying C:\\Users\\MSI\\AppData\\Local\\Temp\\tmpce0rn_bo to cache at C:\\Users\\MSI\\.cache\\torch\\pytorch_fairseq\\e2aab4d600e7568c2d88fc7732130ccc815ea84ec63906cb0913c7a3a4906a2e.0f323dfaed92d080380e63f0291d0f31adfa8c61a62cbcb3cb8114f061be27f7\n",
      "2023-05-01 22:54:40 | INFO | fairseq.file_utils | creating metadata file for C:\\Users\\MSI\\.cache\\torch\\pytorch_fairseq\\e2aab4d600e7568c2d88fc7732130ccc815ea84ec63906cb0913c7a3a4906a2e.0f323dfaed92d080380e63f0291d0f31adfa8c61a62cbcb3cb8114f061be27f7\n",
      "2023-05-01 22:54:40 | INFO | fairseq.file_utils | removing temp file C:\\Users\\MSI\\AppData\\Local\\Temp\\tmpce0rn_bo\n",
      "2023-05-01 22:54:43 | INFO | fairseq.file_utils | https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe not found in cache, downloading to C:\\Users\\MSI\\AppData\\Local\\Temp\\tmpyr5qee2o\n",
      "456318B [00:00, 507565.85B/s]\n",
      "2023-05-01 22:54:45 | INFO | fairseq.file_utils | copying C:\\Users\\MSI\\AppData\\Local\\Temp\\tmpyr5qee2o to cache at C:\\Users\\MSI\\.cache\\torch\\pytorch_fairseq\\b04a6d337c09f464fe8f0df1d3524db88a597007d63f05d97e437f65840cdba5.939bed25cbdab15712bac084ee713d6c78e221c5156c68cb0076b03f5170600f\n",
      "2023-05-01 22:54:45 | INFO | fairseq.file_utils | creating metadata file for C:\\Users\\MSI\\.cache\\torch\\pytorch_fairseq\\b04a6d337c09f464fe8f0df1d3524db88a597007d63f05d97e437f65840cdba5.939bed25cbdab15712bac084ee713d6c78e221c5156c68cb0076b03f5170600f\n",
      "2023-05-01 22:54:45 | INFO | fairseq.file_utils | removing temp file C:\\Users\\MSI\\AppData\\Local\\Temp\\tmpyr5qee2o\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')\n",
    "roberta.eval()  # disable dropout (or leave in train mode to finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2678435f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2678435f",
    "outputId": "76a5a3e9-d136-49ed-f2e1-4a71e6222eca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 18.887764\n",
      "Size (MB): 18.878548\n",
      "Size (MB): 4.722772\n",
      "Size (MB): 309.030356\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "for name, module in roberta_shared.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "       pruned_model= prune.random_unstructured(module, name='weight', amount=0.5)\n",
    "       print_size_of_model(pruned_model)\n",
    "#pruned_model=prune.random_unstructured(roberta_shared, name='weight',amount=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9k_MahkAhOSO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9k_MahkAhOSO",
    "outputId": "64df3052-c38a-42d2-ee94-921b93398399"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge_score) (1.3.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge_score) (1.23.3)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk->rouge_score) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9add713b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b837bb94bdf242389acdbaf6c1165c26",
      "4affeb51ba9146f1afc68d7b193beb79",
      "fe42e446d0e44886881c207da1876d03",
      "c1142f963db64838acff8b0f74de933c",
      "c6c14c0771ea46ac9779e5d9a6254295",
      "bd700ad8beac407d95cb95397bbf0336",
      "c5261c1cb2484a1aa8941dd41b5fdf95",
      "894336241275437ab007d2ff33ba0c76",
      "d7c6e23c372a473eabf3c1b58dd05784",
      "020fd832845a48f6b4d516dc344998ff",
      "de0556b8eefb4e5e951eb82354d0e4d8"
     ]
    },
    "id": "9add713b",
    "outputId": "8382fe15-3691-49a8-a02d-30247db7d49a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfecb6a3f8424bae9c23d7158db34988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import  load_metric\n",
    "# load rouge for validation\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "slgMn6KgBru4",
   "metadata": {
    "id": "slgMn6KgBru4"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cee54376",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "cee54376",
    "outputId": "f3546827-e475-40b6-f1fb-e5c2d0509471"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The batch received was empty, your model won't be able to train on it. Double-check that your training dataset contains keys expected by the model: input_ids,attention_mask,decoder_input_ids,decoder_attention_mask,encoder_outputs,past_key_values,inputs_embeds,decoder_inputs_embeds,labels,use_cache,output_attentions,output_hidden_states,return_dict,kwargs,labels,label,label_ids.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [29], line 27\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#predict_with_generate=True,\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# instantiate trainer\u001b[39;00m\n\u001b[0;32m     20\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     21\u001b[0m      model\u001b[38;5;241m=\u001b[39mroberta_shared,\n\u001b[0;32m     22\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[0;32m     26\u001b[0m )\n\u001b[1;32m---> 27\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:1633\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1630\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1631\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1632\u001b[0m )\n\u001b[1;32m-> 1633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1638\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:1902\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1900\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1902\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1905\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1906\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1907\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1908\u001b[0m ):\n\u001b[0;32m   1909\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1910\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:2638\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2620\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2621\u001b[0m \u001b[38;5;124;03mPerform a training step on a batch of inputs.\u001b[39;00m\n\u001b[0;32m   2622\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2635\u001b[0m \u001b[38;5;124;03m    `torch.Tensor`: The tensor with training loss on this batch.\u001b[39;00m\n\u001b[0;32m   2636\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2637\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m-> 2638\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[0;32m   2641\u001b[0m     loss_mb \u001b[38;5;241m=\u001b[39m smp_forward_backward(model, inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:2585\u001b[0m, in \u001b[0;36mTrainer._prepare_inputs\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2583\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs)\n\u001b[0;32m   2584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2585\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2586\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe batch received was empty, your model won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be able to train on it. Double-check that your \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2587\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining dataset contains keys expected by the model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signature_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_past \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2590\u001b[0m     inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmems\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_past\n",
      "\u001b[1;31mValueError\u001b[0m: The batch received was empty, your model won't be able to train on it. Double-check that your training dataset contains keys expected by the model: input_ids,attention_mask,decoder_input_ids,decoder_attention_mask,encoder_outputs,past_key_values,inputs_embeds,decoder_inputs_embeds,labels,use_cache,output_attentions,output_hidden_states,return_dict,kwargs,labels,label,label_ids."
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    \n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_steps=2, \n",
    "    save_steps=16, \n",
    "    eval_steps=500, \n",
    "    warmup_steps=500, \n",
    "    overwrite_output_dir=True,\n",
    "    save_total_limit=1,\n",
    "    fp16=False, \n",
    "    \n",
    ")\n",
    "#predict_with_generate=True,\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Trainer(\n",
    "     model=roberta_shared,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4615e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "id": "5d4615e2",
    "outputId": "6e2bcef3-9f39-4c32-b779-c38eb8a4eb6c"
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "model = EncoderDecoderModel.from_pretrained(\"/checkpoint-6432\")\n",
    "model.to(\"cuda\")\n",
    "batch_size = 1024\n",
    "\n",
    "# map data correctly\n",
    "def generate_summary(batch):\n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
    "    inputs = tokenizer(batch[\"Text\"], padding=\"max_length\", truncation=True, max_length=40, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(\"cuda\")\n",
    "    attention_mask = inputs.attention_mask.to(\"cuda\")\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    # all special tokens including will be removed\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    batch[\"pred\"] = output_str\n",
    "\n",
    "    return batch\n",
    "results = test_data.map(generate_summary, batched=True, batch_size=batch_size, remove_columns=[\"Text\"])\n",
    "pred_str = results[\"pred\"]\n",
    "label_str = results[\"Summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qcO3dvDhCfte",
   "metadata": {
    "id": "qcO3dvDhCfte"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "020fd832845a48f6b4d516dc344998ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "022715bd72544b6684696f50c663c766": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "12ad0e47332943eab2e0e64eb5135995": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1ad0acfaff4d4f9c9239953071cae73f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4be440f787948d4ba8a0fc70b1e6012",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5cd7e037b9634d1e880a56b88bbbb838",
      "value": 1
     }
    },
    "202288365dce4647aecc93312aabbade": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6a50164c41a4506bae32854979e662f",
      "placeholder": "​",
      "style": "IPY_MODEL_022715bd72544b6684696f50c663c766",
      "value": " 1/1 [00:01&lt;00:00,  1.22s/ba]"
     }
    },
    "22f17594f287485f936e2da26e667ef9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2dba7ebe56cc4cebb99d9b7387211de1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "304942949e3b4409aafce5f341396334": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b82690564f3e42e8a551dc9ddb20128a",
       "IPY_MODEL_e67560d5ba9b4b6092c8cd5e4463e185",
       "IPY_MODEL_f75b43fcd9384117913d68dc351ecdcd"
      ],
      "layout": "IPY_MODEL_6edce8734740439d90f08f086c0d687a"
     }
    },
    "3549f062e24640d083b9aa5969c22907": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c6892695afa4f08ada127db7561e86e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9da71713705b480f8c380779278ca660",
      "placeholder": "​",
      "style": "IPY_MODEL_22f17594f287485f936e2da26e667ef9",
      "value": " 1/1 [00:01&lt;00:00,  1.05s/ba]"
     }
    },
    "446ff07466824959a0a31dded2f73ecc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4affeb51ba9146f1afc68d7b193beb79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd700ad8beac407d95cb95397bbf0336",
      "placeholder": "​",
      "style": "IPY_MODEL_c5261c1cb2484a1aa8941dd41b5fdf95",
      "value": "Downloading: "
     }
    },
    "505bfcaa00bd44a3979b0846c91eb0d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cd7e037b9634d1e880a56b88bbbb838": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5cf434174d4641d18d3f462aa32b05ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_acd66da712b84d239d45b27e987cf0c2",
       "IPY_MODEL_1ad0acfaff4d4f9c9239953071cae73f",
       "IPY_MODEL_202288365dce4647aecc93312aabbade"
      ],
      "layout": "IPY_MODEL_446ff07466824959a0a31dded2f73ecc"
     }
    },
    "5dccc9b45b3649089eb9e41ed93849f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63a4284f715a47b4b04d91efe26f6d22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72c47f55dcfc488cb53ec6597f1cb69e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f5ceae3cf4ca41b08d5278d3ddc871d5",
      "value": 1
     }
    },
    "6edce8734740439d90f08f086c0d687a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72c47f55dcfc488cb53ec6597f1cb69e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "894336241275437ab007d2ff33ba0c76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c02a9c8cb004d42bf6b95c41a6fcf24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9da71713705b480f8c380779278ca660": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ee3a9ef6ddd4d1eb3b30ef6f76657a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_af1c9097edc948eaa77fd5fdd19830e6",
       "IPY_MODEL_63a4284f715a47b4b04d91efe26f6d22",
       "IPY_MODEL_3c6892695afa4f08ada127db7561e86e"
      ],
      "layout": "IPY_MODEL_2dba7ebe56cc4cebb99d9b7387211de1"
     }
    },
    "acd66da712b84d239d45b27e987cf0c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c02a9c8cb004d42bf6b95c41a6fcf24",
      "placeholder": "​",
      "style": "IPY_MODEL_3549f062e24640d083b9aa5969c22907",
      "value": "100%"
     }
    },
    "af1c9097edc948eaa77fd5fdd19830e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_505bfcaa00bd44a3979b0846c91eb0d6",
      "placeholder": "​",
      "style": "IPY_MODEL_d0bf9b559efd419ea54bc03ac8296291",
      "value": "100%"
     }
    },
    "b54ac5c1454243f69a7a448a00a872d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b82690564f3e42e8a551dc9ddb20128a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5dccc9b45b3649089eb9e41ed93849f2",
      "placeholder": "​",
      "style": "IPY_MODEL_d5e549fe79bf4e3f9ac4e640c7215055",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "b837bb94bdf242389acdbaf6c1165c26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4affeb51ba9146f1afc68d7b193beb79",
       "IPY_MODEL_fe42e446d0e44886881c207da1876d03",
       "IPY_MODEL_c1142f963db64838acff8b0f74de933c"
      ],
      "layout": "IPY_MODEL_c6c14c0771ea46ac9779e5d9a6254295"
     }
    },
    "bd700ad8beac407d95cb95397bbf0336": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1142f963db64838acff8b0f74de933c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_020fd832845a48f6b4d516dc344998ff",
      "placeholder": "​",
      "style": "IPY_MODEL_de0556b8eefb4e5e951eb82354d0e4d8",
      "value": " 4.20k/? [00:00&lt;00:00, 157kB/s]"
     }
    },
    "c5261c1cb2484a1aa8941dd41b5fdf95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6a50164c41a4506bae32854979e662f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6c14c0771ea46ac9779e5d9a6254295": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0bf9b559efd419ea54bc03ac8296291": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5e549fe79bf4e3f9ac4e640c7215055": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7c6e23c372a473eabf3c1b58dd05784": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "de0556b8eefb4e5e951eb82354d0e4d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4be440f787948d4ba8a0fc70b1e6012": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e67560d5ba9b4b6092c8cd5e4463e185": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc6da17784e74bde953b00be32dbfad0",
      "max": 501200538,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_12ad0e47332943eab2e0e64eb5135995",
      "value": 501200538
     }
    },
    "ea5f21dbb9c24b3ca8d6ff5671013768": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5ceae3cf4ca41b08d5278d3ddc871d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f75b43fcd9384117913d68dc351ecdcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b54ac5c1454243f69a7a448a00a872d2",
      "placeholder": "​",
      "style": "IPY_MODEL_ea5f21dbb9c24b3ca8d6ff5671013768",
      "value": " 501M/501M [00:04&lt;00:00, 113MB/s]"
     }
    },
    "fc6da17784e74bde953b00be32dbfad0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe42e446d0e44886881c207da1876d03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_894336241275437ab007d2ff33ba0c76",
      "max": 1656,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7c6e23c372a473eabf3c1b58dd05784",
      "value": 1656
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
